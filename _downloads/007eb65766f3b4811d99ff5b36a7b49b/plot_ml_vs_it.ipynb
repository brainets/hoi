{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Machine-learning vs. Information theoretic approaches for HOI\n\nThis example compares Machine-learning and Information theoretic approaches to\ninvestigate Higher Order Interactions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.model_selection import cross_val_score\n\nfrom hoi.metrics import GradientOinfo\n\nplt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data simulation\n\nLet's start by creating a function that simulates higher-order interactions\nbetween a multivariate variable $X={X_{1}, ..., X_{N}}$ and a\nunivariate variable $Y$. We are then going to create redundant and\nsynergistic relationships between $X$ and $Y$. To introduce\nredundancy between the two, each $X_{i}$ is going to receive a copy of\n$Y$. To create synergy, each $X_{i}$ is going to encode different\nparts of $Y$ so that $Y$ can only be fully known when all the\n$X_{i}$ are provided. For further information about how to\nsimulate redundant and synergistic interactions, checkout the example\n`sphx_glr_auto_examples_tutorials_plot_sim_red_syn.py`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def simulate_data(\n    n_samples=300,\n    n_x=3,\n    n_times=100,\n    t_start=40,\n    t_end=60,\n    rel_type=\"redundancy\",\n    rel_strength=0.2,\n):\n    \"\"\"Data simulation.\n\n    Parameters\n    ----------\n    n_samples : int, 300\n        Number of samples in x and y\n    n_x : int, 3\n        Number of features in x\n    n_times : int, 100\n        Number of time points in x\n    t_start : int, 40\n        Time sample at which the relation between x and y starts\n    t_end : int, 60\n        Time sample at which the relation between x and y ends\n    rel_type : {\"redundancy\", \"synergy\"}\n        Specify whether the nature of the relationship between x and y. Use\n        either \"redundancy\" or \"synergy\"\n    rel_strength : float, 0.2\n        Strength of the statistical dependency between x and y\n\n    Returns\n    -------\n    x : array_like\n        Array of shape (n_samples, n_x, n_times)\n    y : array_like\n        Target array of shape (n_samples)\n    \"\"\"\n    assert rel_type in [\"redundancy\", \"synergy\"]\n\n    sl = slice(t_start, t_end)\n    hann = np.hanning(t_end - t_start)\n    y = np.random.permutation([0] * n_samples + [1] * n_samples)\n    y_norm = 2 * y - 1\n\n    if rel_type == \"redundancy\":\n        x = np.random.rand(2 * n_samples, n_x, n_times)\n        x[..., sl] += (\n            rel_strength * y_norm.reshape(-1, 1, 1) * hann.reshape(1, 1, -1)\n        )\n    elif rel_type == \"synergy\":\n        x = np.random.rand(2 * n_samples, n_x, n_times)\n        trial_blocks = np.array_split(np.arange(n_samples * 2), n_x)\n        for n_r in range(n_x):\n            _trials = trial_blocks[n_r]\n            x[_trials, n_r, sl] += (\n                rel_strength\n                * y_norm[_trials].reshape(-1, 1)\n                * hann.reshape(1, -1)\n            )\n\n    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can create two pairs of variables $(X_{red}, Y_{red})$ and\n$(X_{syn}, Y_{syn})$ with respectively redundant and synergistic\nrelationships between them\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_red, y_red = simulate_data(rel_type=\"redundancy\", rel_strength=0.2)\nx_syn, y_syn = simulate_data(rel_type=\"synergy\", rel_strength=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_xy(x, y):\n    for n_y, u in enumerate(np.unique(y)):\n        for n_x in range(x.shape[1]):\n            u_x = x[y == u, n_x, :]\n            x_m = u_x.mean(0)\n            plt.plot(x_m, color=f\"C{n_y}\", label=rf\"$X[Y == {u}, {n_x}, :]$\")\n    plt.legend()\n\nfig, axs = plt.subplots(2, 1, figsize=(8, 12), sharex=True, sharey=True)\naxs = np.ravel(axs)\nplt.sca(axs[0])\nplot_xy(x_red, y_red)\nplt.title(\"Redundant interactions\")\nplt.sca(axs[1])\nplot_xy(x_syn, y_syn)\nplt.title(\"Synergistic interactions\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decoding Y using X\n\nNow let's try to decode the $Y$ variable using $X$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def decode_y(x, y):\n    clf = LinearDiscriminantAnalysis()\n    _, n_x, n_times = x.shape\n    da = np.zeros((n_x + 1, n_times))\n    for t in range(n_times):\n        for n_r in range(n_x):\n            da[n_r, t] = cross_val_score(clf, x[:, n_r, [t]], y, cv=5).mean()\n        da[-1, t] = cross_val_score(clf, x[:, :, t], y, cv=5).mean()\n\n    return 100 * da\n\n\ndef plot_decoding(da):\n    for k in range(da.shape[0] - 1):\n        plt.plot(da[k, :], color=\"k\", label=r\"$DA_{X_{%i}}$\" % (k + 1))\n    plt.plot(da[-1, :], color=\"C0\", label=r\"$DA_{X_{1}, ..., X_{N}}$\", lw=4)\n    plt.legend()\n\nfig, axs = plt.subplots(2, 1, figsize=(8, 12), sharex=True, sharey=True)\naxs = np.ravel(axs)\nplt.sca(axs[0])\nplot_decoding(decode_y(x_red, y_red))\nplt.ylabel(\"Decoding accuracy [%]\")\nplt.title(\"Redundant interactions\", fontweight=\"bold\")\nplt.sca(axs[1])\nplot_decoding(decode_y(x_syn, y_syn))\nplt.ylabel(\"Decoding accuracy [%]\")\nplt.title(\"Synergistic interactions\", fontweight=\"bold\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, using machine-learning we can decode the $Y$ variable\nwith a decoding accuracy of ~90% when there's either redundant or synergistic\ninteractions between $X$ and $Y$\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using information-theoretic approaches\n\nNow let's information-theoretic approaches. The question we try to answer\nhere is whether the $X_{i}$ are carrying redundant or synergistic\ninformation about $Y$. To answer this question we are going to use the\nGradient Oinfo.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def it(x, y):\n    model = GradientOinfo(x, y, verbose=False)\n    return model.fit(minsize=3, maxsize=3)\n\n\nfig, axs = plt.subplots(2, 1, figsize=(8, 12), sharex=True, sharey=True)\naxs = np.ravel(axs)\nplt.sca(axs[0])\nplt.plot(it(x_red, y_red).squeeze())\nplt.ylabel(r\"$\\partial \\Omega_{[X_{1}, ..., X_{N}]}$ [Bits]\")\nplt.title(\"Redundant interactions\", fontweight=\"bold\")\nplt.sca(axs[1])\nplt.plot(it(x_syn, y_syn).squeeze())\nplt.ylabel(r\"$\\partial \\Omega_{[X_{1}, ..., X_{N}]}$ [Bits]\")\nplt.title(\"Synergistic interactions\", fontweight=\"bold\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We retrieve the bump of information around sample 50 however this time, the\nbump is positive in case of redundant interactions and negative in case of\nsynergistic interactions.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}