{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Redundancy and Synergy MMI\n\nThis example illustrates how to use and interpret synergy and redundancy\ncomputed using the Minimum Mutual Information (MMI) approach to \napproximate the redundancy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom hoi.metrics import RedundancyMMI, SynergyMMI\nfrom hoi.plot import plot_landscape\nfrom hoi.utils import get_nbest_mult\n\nplt.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definition\n\n:term:`Synergy` and :term:`redundancy` measures directly, respectively the ammount\nof synergy and redundancy carried by a group of variable $S$\nabout a target variable $Y$. Synergy is defined as follow :\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\begin{align}Syn(S; Y) \\equiv I(S; Y) - \\max_{x_{i}\\in S} I(S_{-i}; Y)\\end{align}\n\nwith : $S = x_{1}, ..., x_{n}$ and\n$S_{-i} = x_{1}, ..., x_{i-1}, x_{1+1}, ..., x_{n}$\n\nPositive values of Synergy stand for the presence of an higher information\nabout $Y$ when considering all the variables in $S$ with\nrespect to when considering only a subgroup of $n-1$.\n\nRedundancy, in the approximation based on the Minimum Mutual Information\n(MMI) framework, is computed as follow :\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\begin{align}Red(S; Y) \\equiv \\min_{x_{i}\\in S} I(X_{i}; Y)\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulate univariate redundancy\n\nA very simple way to simulate redundancy is to observe that if a triplet of\nvariables $X_{1}, X_{2}, X_{3}$ receive a copy of a variable $Y$,\nwe will observe redundancy between $X_{1}, X_{2}, X_{3}$ and $Y$.\nFor further information about how to simulate redundant and synergistic\ninteractions, checkout the example\n`sphx_glr_auto_examples_tutorials_plot_sim_red_syn.py`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# lets start by simulating a variable x with 200 samples and 7 features\nx = np.random.rand(200, 7)\n\n# now we can also generate a univariate random variable `Y`\ny = np.random.rand(x.shape[0])\n\n# we now send the variable y in the column (1, 3, 5) of `X`\nx[:, 1] += y\nx[:, 3] += y\nx[:, 5] += y\n\n# define the RSI model and launch it\nmodel = RedundancyMMI(x, y)\nhoi = model.fit(minsize=3, maxsize=5)\n\n# now we can take a look at the multiplets with the highest and lowest values\n# of RSI. We will only select the multiplets of size 3 here\ndf = get_nbest_mult(hoi, model=model, minsize=3, maxsize=3, n_best=3)\nprint(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "as you see from the printed table, the multiplet with the lowest (i.e. the\nmost redundant multiplets) is (1, 3, 5).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulate multivariate redundancy\n\nIn the example above, we simulated a univariate $Y$ variable (i.e.\nsingle column). However, it's possible to simulate a multivariate variable.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# simulate x again\nx = np.random.rand(200, 7)\n\n# simulate a bivariate y variable\ny = np.c_[np.random.rand(x.shape[0]), np.random.rand(x.shape[0])]\n\n# we introduce redundancy between the triplet (1, 3, 5) and the first column of\n# `Y` and between (0, 2, 6) and the second column of `Y`.\nx[:, 1] += y[:, 0]\nx[:, 3] += y[:, 0]\nx[:, 5] += y[:, 0]\nx[:, 0] += y[:, 1]\nx[:, 2] += y[:, 1]\nx[:, 6] += y[:, 1]\n\n# define the Redundancy, launch it and inspect the best multiplets\nmodel = RedundancyMMI(x, y)\nhoi = model.fit(minsize=3, maxsize=5)\ndf = get_nbest_mult(hoi, model=model, minsize=3, maxsize=3, n_best=5)\nprint(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is important to notice that in this case the redundancy it is not able to\nfind only the two multiplets in which we generate redundancy, but instead\nall the possible combination of the six variables in which a part of `Y`\nwas copied are resulting redundant. This follows directly by the definition\nof redundancy with the MMI approximation. It is important to remember this\nlimitation when leveraging its results and eventually\nconsider a double check with other metrics, as RSI or O-information gradient.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulate univariate and multivariate synergy\n\nLets move on to the simulation of synergy that is a bit more subtle. One way\nof simulating synergy is to go the other way of redundancy, meaning we are\ngoing to add features of x inside `Y`. That way, we can only retrieve the `Y`\nvariable by knowing the subset of `X`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# simulate the variable x\nx = np.random.rand(200, 7)\n\n# synergy between (0, 3, 5) and 5\ny = x[:, 0] + x[:, 3] + x[:, 5]\n\n# define the Synergy, launch it and inspect the best multiplets\nmodel = SynergyMMI(x, y)\nhoi = model.fit(minsize=3, maxsize=5)\ndf = get_nbest_mult(hoi, model=model, minsize=3, maxsize=3, n_best=3)\nprint(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "as we can see here, the highest values of higher-order interactions\n(i.e. synergy) is achieved for the multiplet (0, 3, 5). Now we can do the\nsame for multivariate synergy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# simulate the variable `X`\nx = np.random.rand(200, 7)\n\n# simulate y and introduce synergy between the subset (0, 3, 5) of `X` and the\n# subset (1, 2, 6)\ny = np.c_[x[:, 0] + x[:, 3] + x[:, 5], x[:, 1] + x[:, 2] + x[:, 6]]\n\n# define the Synergy, launch it and inspect the best multiplets\nmodel = SynergyMMI(x, y)\nhoi = model.fit(minsize=3, maxsize=5)\ndf = get_nbest_mult(hoi, model=model, minsize=3, maxsize=3, n_best=3)\nprint(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combining redundancy and synergy\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# simulate the variable x and y\nx = np.random.rand(200, 7)\ny = np.random.rand(200, 2)\n\n# synergy between (0, 1, 2) and the first column of `Y`\ny[:, 0] = x[:, 0] + x[:, 1] + x[:, 2]\n\n# redundancy between (3, 4, 5) and the second column of `X`\nx[:, 3] = y[:, 1]\nx[:, 4] = y[:, 1]\nx[:, 5] = y[:, 1]\n\n# define the Synergy, launch it and inspect the best multiplets\nmodel_syn = SynergyMMI(x, y)\nhoi_syn = model_syn.fit(minsize=3, maxsize=5)\ndf = get_nbest_mult(hoi_syn, model=model, minsize=3, maxsize=3, n_best=3)\nprint(\" \")\nprint(\"Synergy results\")\nprint(\" \")\nprint(df)\n\n# define the Synergy, launch it and inspect the best multiplets\nmodel_red = RedundancyMMI(x, y)\nhoi_red = model_red.fit(minsize=3, maxsize=5)\ndf = get_nbest_mult(hoi_red, model=model, minsize=3, maxsize=3, n_best=3)\nprint(\" \")\nprint(\"Redundancy results\")\nprint(\" \")\nprint(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting redundancy\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_landscape(\n    hoi_red,\n    model_red,\n    kind=\"scatter\",\n    undersampling=False,\n    plt_kwargs=dict(cmap=\"turbo\"),\n)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting synergy\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_landscape(\n    hoi_syn,\n    model_syn,\n    kind=\"scatter\",\n    undersampling=False,\n    plt_kwargs=dict(cmap=\"turbo\"),\n)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}