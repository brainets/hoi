{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Comparison of MI estimators with high-dimensional data\n\nIn this example, we are going to compare estimators of mutual-information (MI)\nwith high-dimensional data.\nIn particular, the MI between variables sampled from a multinormal distribution\ncan be estimated theoretically. In this this tutorial we are going to:\n\n1. Simulate data sampled from a \"splitted\" multivariate normal distribution.\n2. Define estimators of MI.\n3. Compute the MI for a varying number of samples.\n4. See if the computed MI converge towards the theoretical value.\n\nThis example is inspired from a similar simulation done by\nCzyz et al., NeurIPS 2023 :cite:`czyz2024beyond`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom hoi.core import get_mi\n\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definition of MI estimators\n\nWe are going to use the GCMI (Gaussian Copula Mutual Information), KNN\n(k Nearest Neighbor) and histogram estimator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# list of estimators to compare\nmetrics = {\n    \"GCMI\": get_mi(\"gc\", biascorrect=False),\n    \"KNN-3\": get_mi(\"knn\", k=3),\n    \"KNN-10\": get_mi(\"knn\", k=10),\n    \"Histogram\": get_mi(\"histogram\", n_bins=3),\n}\n\n# number of samples to simulate data\nn_samples = np.geomspace(20, 1000, 15).astype(int)\n\n# number of repetitions to estimate the percentile interval\nn_repeat = 10\n\n\n# plotting function\ndef plot(mi, mi_theoric, ax):\n    \"\"\"Plotting function.\"\"\"\n    for n_m, metric_name in enumerate(mi.keys()):\n        # get the entropies\n        x = mi[metric_name]\n\n        # get the color\n        color = f\"C{n_m}\"\n\n        # estimate lower and upper bounds of the [5, 95]th percentile interval\n        x_low, x_high = np.percentile(x, [5, 95], axis=0)\n\n        # plot the MI as a function of the number of samples and interval\n        ax.plot(n_samples, x.mean(0), color=color, lw=2, label=metric_name)\n        ax.fill_between(n_samples, x_low, x_high, color=color, alpha=0.2)\n\n    # plot the theoretical value\n    ax.axhline(mi_theoric, linestyle=\"--\", color=\"k\", label=\"Theoretical MI\")\n    ax.legend()\n    ax.set_xlabel(\"Number of samples\")\n    ax.set_ylabel(\"Mutual-information [bits]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MI of data sampled from splitted multinormal distribution\n\nGiven two variables $X \\sim \\mathcal{N}(\\vec{\\mu_{x}}, \\Sigma_{x})$ and\n$Y \\sim \\mathcal{N}(\\vec{\\mu_{y}}, \\Sigma_{y})$, linked by a covariance\n$C$ the theoretical MI in bits is defined by :\n\n\\begin{align}I(X; Y) = \\frac{1}{2} \\times log_{2}(\\frac{|\\Sigma_{x}||\\Sigma_{y}|}{|\\Sigma|})\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# function for creating the covariance matrix with differnt modes\ndef create_cov_matrix(n_dims, cov, mode=\"dense\", k=None):\n    \"\"\"Create a covariance matrix.\"\"\"\n    # variance of x and y, for each dimension, 1\n    cov_matrix = np.eye(2 * n_dims)\n    if mode == \"dense\":\n        # all dimensions, but diagonal, with covariance cov\n        cov_matrix += cov\n        cov_matrix[np.diag_indices(2 * n_dims)] = 1\n    elif mode == \"sparse\":\n        # only pairs xi, yi with i < k have covariance cov\n        k = k if k is not None else n_dims\n        for i in range(n_dims):\n            if i < k:\n                cov_matrix[i, i + n_dims] = cov\n                cov_matrix[i + n_dims, i] = cov\n\n    return cov_matrix\n\n\ndef compute_true_mi(cov_matrix):\n    \"\"\"Compute the true MI (bits).\"\"\"\n    n_dims = cov_matrix.shape[0] // 2\n    det_x = np.linalg.det(cov_matrix[n_dims:, n_dims:])\n    det_y = np.linalg.det(cov_matrix[:n_dims, :n_dims])\n    det_xy = np.linalg.det(cov_matrix)\n    return 0.5 * np.log2(det_x * det_y / det_xy)\n\n\n# number of dimensions per variable\nn_dims = 4\n# mean\nmu = [0.0] * n_dims * 2\n# covariance\ncovariance = 0.6\n\n# modes for the covariance matrix:\n# - dense: off diagonal elements have specified covariance\n# - sparse: only pairs xi, yi with i < k have specified covariance\nmodes = [\"dense\", \"sparse\"]\n# number of pairs with specified covariance\nk = n_dims\n\nfig = plt.figure(figsize=(10, 5))\n# compute mi using various metrics\nmi = {k: np.zeros((n_repeat, len(n_samples))) for k in metrics.keys()}\nfor i, mode in enumerate(modes):\n    cov_matrix = create_cov_matrix(n_dims, covariance, mode=mode)\n    # define the theoretic MI\n    mi_theoric = compute_true_mi(cov_matrix)\n    ax = fig.add_subplot(1, 2, i + 1)\n\n    for n_s, s in enumerate(n_samples):\n        for n_r in range(n_repeat):\n            # generate samples from joint gaussian distribution\n            fx = np.random.multivariate_normal(mu, cov_matrix, s)\n            for metric, fcn in metrics.items():\n                # extract x and y\n                x = fx[:, :n_dims].T\n                y = fx[:, n_dims:].T\n                # compute mi\n                mi[metric][n_r, n_s] = fcn(x, y)\n\n    # plot the results\n    plot(mi, mi_theoric, ax)\n    ax.title.set_text(f\"Mode: {mode}\")\n\nfig.suptitle(\n    \"Comparison of MI estimators when\\nthe data is high-dimensional\",\n    fontweight=\"bold\",\n)\nfig.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}