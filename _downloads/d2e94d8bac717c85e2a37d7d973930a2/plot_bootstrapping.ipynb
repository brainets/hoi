{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Bootstrapping and confidence interval\n\nThis example illustrates how to estimate the confidence interval around\nHigher Order Interactions. In addition, it also shows how the bootstrapping can\nbe used to fix the spatial spreading limitation of the O-information. For\nfurther information, checkout the example\n`sphx_glr_auto_examples_metrics_plot_infotopo.py`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom hoi.metrics import Oinfo\nfrom hoi.plot import plot_landscape\nfrom hoi.utils import get_nbest_mult\n\nfrom sklearn.utils import resample\n\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## O-information : Redundancy and synergy spread to higher orders\n\nAs illustrated in the example\n`sphx_glr_auto_examples_metrics_plot_infotopo.py`, when using the\n:class:`hoi.metrics.Oinfo`, the redundancy define at one order is going to\nspread across orders. As a reminder, let's simulate some simple data, a\n4-nodes network with 200 samples. For further information about how to\nsimulate redundant and synergistic interactions, checkout the example\n`sphx_glr_auto_examples_tutorials_plot_sim_red_syn.py`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# define the number of samples and nodes in the network\nn_samples = 200\nn_nodes = 4\n\n# simulate some data\nx = np.random.rand(n_samples, n_nodes)\n\n# create redundancy between nodes (0, 1, 2)\nx[:, 1] += x[:, 0]\nx[:, 2] += x[:, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can estimate the O-information and plot the landscape of hoi\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# compute the o-information\nmodel = Oinfo(x, verbose=False)\nhoi = model.fit(method=\"gc\", minsize=3)\n\n# plot the landscape\nplot_landscape(\n    hoi, model=model, kind=\"scatter\", plt_kwargs=dict(cmap=\"Spectral_r\")\n)\n\n# also print the hoi with highest values\nprint(get_nbest_mult(hoi, model=model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see from the printed table and the landscape, the highest\nO-information is achieved for the multiplet (0, 1, 2) at order 3 and the\nmultiplet (0, 1, 2, 3, 4) at order 4. However, we simulated redundancy only\nbetween the nodes (0, 1, 2). To fix this with non-parametric statistics, we\nare going to use bootstrapping to estimate the confidence interval\nsurrounding each estimation of hoi.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimation of the confidence interval using a bootstrapping approach\n\nTo estimate the confidence interval, we are going to repeat the computations\nof hoi by randomly sampling the samples. To this end we are going to use the\nresample method of scikit-learn\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute bootstrap\nRegarding the number of bootstraps, the higher the better but is also more\ncomputationally intensive. Here we are going to use 20 to keep the example\nfast. We recommand at least 200-1000 bootstraps.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# define the number of bootstrap.\nn_boots = 20\n\n# define an empty list of hoi\nhoi = []\n\n# repeat the computation of hoi `n_boots` times\nfor n_b in range(20):\n    print(f\"Bootstrap {n_b + 1} / {n_boots}\", end=\"\\r\")\n\n    # define a random list of trials\n    samples = resample(\n        np.arange(n_samples), n_samples=n_samples, random_state=n_b\n    )\n\n    # compute the o-info using the subselected trials\n    _hoi = model.fit(method=\"gc\", samples=samples, minsize=3).squeeze()\n\n    # append to the list\n    hoi.append(_hoi)\n\n# stack the bootstraps over the first dimension\nhoi = np.stack(hoi, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot the O-information with the confidence interval\nNow we can plot the O-information and its confidence interval.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# compute the mean of the o-information over the bootstraps\nhoi_m = hoi.mean(0)\n\n# get the [5, 95]% confidence interval\np_low, p_high = np.percentile(hoi, [5, 95], axis=0)\n\n# plot the results\nx_axis = np.arange(hoi_m.shape[0])\nax = plt.step(x_axis, hoi_m, where=\"mid\", lw=3)\nplt.fill_between(x_axis, p_low, p_high, alpha=0.3, step=\"mid\")\nplt.xticks(x_axis)\nplt.gca().set_xticklabels(\n    [str(m[0:o]) for m, o in zip(model.multiplets, model.order)], rotation=45\n)\nplt.xlabel(\"Multiplet\")\nplt.ylabel(\"Oinfo [bits]\")\nplt.title(\"O-information with [5, 95]% confidence interval\", fontweight=\"bold\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The plot above depicts the average of the O-information over the bootstraps\nas a bold thick line for all of the multiplets and the shaded area represents\nthe confidence interval. As we can see now, the confidence surrounding the\nmultiplet (0, 1, 2, 3) is not really different from the multiplet (0, 1, 2).\nTherefore, we can say that the redundancy is mainly carried by the triplet\n(0, 1, 2) and the addition of the node 3 doesn't bring much. For comparison,\nwe are going to use the exact same code except that this time, we are going\nto create redundancy between the quadruplet (0, 1, 2, 3).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# simulate some data\nx = np.random.rand(n_samples, n_nodes)\n\n# create redundancy between nodes (0, 1, 2, 3)\nx[:, 1] += x[:, 0]\nx[:, 2] += x[:, 0]\nx[:, 3] += x[:, 0]\n\n# initialize the o-information model\nmodel = Oinfo(x, verbose=False)\n\n# define an empty list of hoi\nhoi = []\n\n# repeat the computation of hoi `n_boots` times\nfor n_b in range(20):\n    print(f\"Bootstrap {n_b + 1} / {n_boots}\", end=\"\\r\")\n\n    # define a random list of trials\n    samples = resample(\n        np.arange(n_samples), n_samples=n_samples, random_state=n_b\n    )\n\n    # compute the o-info using the subselected trials\n    _hoi = model.fit(method=\"gc\", samples=samples, minsize=3).squeeze()\n\n    # append to the list\n    hoi.append(_hoi)\n\n# stack the boostraps over the first dimension\nhoi = np.stack(hoi, axis=0)\n\n# compute the mean of the o-information over the bootstraps\nhoi_m = hoi.mean(0)\n\n# get the [5, 95]% confidence interval\np_low, p_high = np.percentile(hoi, [5, 95], axis=0)\n\n# plot the results\nx_axis = np.arange(hoi_m.shape[0])\nax = plt.step(x_axis, hoi_m, where=\"mid\", lw=3)\nplt.fill_between(x_axis, p_low, p_high, alpha=0.3, step=\"mid\")\nplt.xticks(x_axis)\nplt.gca().set_xticklabels(\n    [str(m[0:o]) for m, o in zip(model.multiplets, model.order)], rotation=45\n)\nplt.xlabel(\"Multiplet\")\nplt.ylabel(\"Oinfo [bits]\")\nplt.title(\"O-information with [5, 95]% confidence interval\", fontweight=\"bold\")\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This time, the O-information and confidence interval surrounding the\nmultiplet (0, 1, 2, 3) doesn't includes the confidence interval of lower\norder. Therefore we can conclude that the redundancy lies in the quadruplet\nand not in any of the triplets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = 2"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}