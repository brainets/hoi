
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/tutorials/tutorial_core.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_tutorials_tutorial_core.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_tutorials_tutorial_core.py:


Core information theoretical metrics
====================================

This tutorial guides you through the core information theoretical metrics
available. These metrics are the entropy and the mutual information.

.. GENERATED FROM PYTHON SOURCE LINES 8-12

.. code-block:: Python

    import numpy as np
    from hoi.core import get_entropy
    from hoi.core import get_mi


.. GENERATED FROM PYTHON SOURCE LINES 13-25

Entropy
-------

The fundamental information theoretical metric is the entropy. Most of the
other higher-order metrics of information theory defined in HOI are based on
the entropy.

In HOI there are 4 different methods to compute the entropy, in this tutorial
we will use the estimation based on the Gaussian Copula estimation.

Let's start by extracting a sample `x` from a multivariate Gaussian distribution
with zero mean and unit variance:

.. GENERATED FROM PYTHON SOURCE LINES 25-29

.. code-block:: Python


    D = 3
    x = np.random.normal(size=(D, 1000))


.. GENERATED FROM PYTHON SOURCE LINES 30-34

Now we can compute the entropy of `x`. We use the function `get_entropy` to
build a callable function to compute the entropy. The function `get_entropy`
takes as input the method to use to compute the entropy. In this case we use
the Gaussian Copula estimation, so we set the method to `"gcmi":

.. GENERATED FROM PYTHON SOURCE LINES 34-37

.. code-block:: Python


    entropy = get_entropy(method="gcmi")


.. GENERATED FROM PYTHON SOURCE LINES 38-41

Now we can compute the entropy of `x` by calling the function `entropy`. This
function takes as input an array of data of shape `(n_features, n_samples)`. For
the Gaussian Copula estimation, the entropy is computed in bits. We have:

.. GENERATED FROM PYTHON SOURCE LINES 41-44

.. code-block:: Python


    print("Entropy of x: %.2f" % entropy(x))


.. GENERATED FROM PYTHON SOURCE LINES 45-51

For comparison, we can compute the entropy of a multivariate Gaussian with
the analytical formula, which is:
.. math::
  H(X) = \frac{1}{2} \log \left( (2 \pi e)^D \det(\Sigma) \right)
where :math:`D` is the dimensionality of the Gaussian and :math:`\Sigma` is
the covariance matrix of the Gaussian. We have:

.. GENERATED FROM PYTHON SOURCE LINES 51-58

.. code-block:: Python


    C = np.cov(x, rowvar=True)
    entropy_analytical = (
        0.5 * (np.log(np.linalg.det(C)) + D * (1 + np.log(2 * np.pi)))
    ) / np.log(2)
    print("Analytical entropy of x: %.2f" % entropy_analytical)


.. GENERATED FROM PYTHON SOURCE LINES 59-70

We see that the two values are very close.

Mutual information
------------------

The mutual information is another fundamental information theoretical metric.
In this tutorial we will compute the mutual information between two variables
`x` and `y`. `x` is a multivariate Gaussian with zero mean and unit variance,
while `y` is a multivariate uniform distribution in the interval :math:`[0,1]`.
Since the two variables are independent, the mutual information between them is expected
to be zero.

.. GENERATED FROM PYTHON SOURCE LINES 70-77

.. code-block:: Python


    D = 3
    x = np.random.normal(size=(D, 1000))
    y = np.random.rand(D, 1000)

    mi = get_mi(method="gcmi")
    print("Mutual information between x and y: %.2f" % mi(x, y))

**Estimated memory usage:**  0 MB


.. _sphx_glr_download_auto_examples_tutorials_tutorial_core.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: tutorial_core.ipynb <tutorial_core.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: tutorial_core.py <tutorial_core.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
